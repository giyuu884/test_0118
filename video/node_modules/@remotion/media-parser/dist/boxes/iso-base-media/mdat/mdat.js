"use strict";
Object.defineProperty(exports, "__esModule", { value: true });
exports.parseMdat = void 0;
const convert_audio_or_video_sample_1 = require("../../../convert-audio-or-video-sample");
const get_tracks_1 = require("../../../get-tracks");
const get_sample_positions_from_track_1 = require("../get-sample-positions-from-track");
const traversal_1 = require("../traversal");
const parseMdat = async ({ data, size, fileOffset, existingBoxes, state, signal, maySkipSampleProcessing, }) => {
    const alreadyHas = (0, get_tracks_1.hasTracks)({
        type: 'iso-base-media',
        boxes: existingBoxes,
    }, state);
    if (!alreadyHas) {
        if (maySkipSampleProcessing) {
            data.discard(size - (data.counter.getOffset() - fileOffset));
            return Promise.resolve({
                type: 'mdat-box',
                boxSize: size,
                status: 'samples-skipped',
                fileOffset,
            });
        }
        data.discard(size - (data.counter.getOffset() - fileOffset));
        data.disallowDiscard();
        return Promise.resolve({
            type: 'mdat-box',
            boxSize: size,
            status: 'samples-buffered',
            fileOffset,
        });
    }
    const tracks = (0, get_tracks_1.getTracks)({ type: 'iso-base-media', boxes: existingBoxes }, state);
    const allTracks = [
        ...tracks.videoTracks,
        ...tracks.audioTracks,
        ...tracks.otherTracks,
    ];
    const flatSamples = allTracks
        .map((track) => {
        const samplePositions = (0, get_sample_positions_from_track_1.getSamplePositionsFromTrack)(track.trakBox, (0, traversal_1.getMoofBox)(existingBoxes));
        if (!samplePositions) {
            throw new Error('No sample positions');
        }
        return samplePositions.map((samplePosition) => {
            return {
                track: { ...track },
                samplePosition,
            };
        });
    })
        .flat(1);
    while (true) {
        if (signal && signal.aborted) {
            break;
        }
        const samplesWithIndex = flatSamples.find((sample) => {
            return sample.samplePosition.offset === data.counter.getOffset();
        });
        if (!samplesWithIndex) {
            // There are various reasons why in mdat we find weird stuff:
            // - iphonevideo.hevc has a fake hoov atom which is not mapped
            // - corrupted.mp4 has a corrupt table
            const nextSample_ = flatSamples
                .filter((s) => s.samplePosition.offset > data.counter.getOffset())
                .sort((a, b) => a.samplePosition.offset - b.samplePosition.offset)[0];
            if (nextSample_) {
                data.discard(nextSample_.samplePosition.offset - data.counter.getOffset());
                continue;
            }
            else {
                const bytesRemaining = size + fileOffset - data.counter.getOffset();
                data.discard(bytesRemaining);
                break;
            }
        }
        if (data.bytesRemaining() < samplesWithIndex.samplePosition.size) {
            break;
        }
        const bytes = data.getSlice(samplesWithIndex.samplePosition.size);
        const { cts, dts, duration } = samplesWithIndex.samplePosition;
        if (samplesWithIndex.track.type === 'audio') {
            await state.callbacks.onAudioSample(samplesWithIndex.track.trackId, (0, convert_audio_or_video_sample_1.convertAudioOrVideoSampleToWebCodecsTimestamps)({
                data: bytes,
                timestamp: cts,
                duration,
                cts,
                dts,
                trackId: samplesWithIndex.track.trackId,
                type: samplesWithIndex.samplePosition.isKeyframe ? 'key' : 'delta',
                offset: samplesWithIndex.samplePosition.offset,
                timescale: samplesWithIndex.track.timescale,
            }, samplesWithIndex.track.timescale));
        }
        if (samplesWithIndex.track.type === 'video') {
            await state.callbacks.onVideoSample(samplesWithIndex.track.trackId, (0, convert_audio_or_video_sample_1.convertAudioOrVideoSampleToWebCodecsTimestamps)({
                data: bytes,
                timestamp: cts,
                duration,
                cts,
                dts,
                trackId: samplesWithIndex.track.trackId,
                type: samplesWithIndex.samplePosition.isKeyframe ? 'key' : 'delta',
                offset: samplesWithIndex.samplePosition.offset,
                timescale: samplesWithIndex.track.timescale,
            }, samplesWithIndex.track.timescale));
        }
        const remaining = size - (data.counter.getOffset() - fileOffset);
        data.removeBytesRead();
        if (remaining === 0) {
            break;
        }
    }
    return Promise.resolve({
        type: 'mdat-box',
        boxSize: size,
        status: 'samples-processed',
        fileOffset,
    });
};
exports.parseMdat = parseMdat;
